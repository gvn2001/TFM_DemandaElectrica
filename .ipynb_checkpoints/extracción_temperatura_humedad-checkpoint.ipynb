{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def obtener_datos_climaticos(fecha_inicio, fecha_fin, api_key):\n",
    "    # URL de la API inicial\n",
    "    url = f\"https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos/fechaini/{fecha_inicio}/fechafin/{fecha_fin}/todasestaciones\"\n",
    "    \n",
    "    # Encabezados de la solicitud\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'api_key': api_key\n",
    "    }\n",
    "\n",
    "    # Realizar la solicitud GET inicial\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Verificar el estado de la respuesta\n",
    "    if response.status_code == 200:\n",
    "        # Convertir la respuesta a JSON\n",
    "        data = response.json()\n",
    "        \n",
    "        # Obtener la URL de los datos reales\n",
    "        datos_url = data.get('datos')\n",
    "        \n",
    "        if datos_url:\n",
    "            # Realizar la segunda solicitud GET para obtener los datos reales\n",
    "            response_datos = requests.get(datos_url)\n",
    "            \n",
    "            if response_datos.status_code == 200:\n",
    "                # Extraer los datos en formato JSON\n",
    "                datos_reales = response_datos.json()\n",
    "                \n",
    "                # Verificar si datos_reales es una lista y convertirla a DataFrame\n",
    "                if isinstance(datos_reales, list):\n",
    "                    df = pd.DataFrame(datos_reales)\n",
    "                    \n",
    "                    # Filtrar el DataFrame para excluir las provincias no deseadas\n",
    "                    provincias_no_deseadas = ['ILLES BALEARS', 'STA. CRUZ DE TENERIFE', 'LAS PALMAS', 'CEUTA', 'MELILLA']\n",
    "                    df_filtrado = df[~df['provincia'].isin(provincias_no_deseadas)].copy()\n",
    "                    \n",
    "                    # Seleccionar solo los campos deseados\n",
    "                    df_final = df_filtrado[['fecha', 'tmed', 'hrMedia', 'provincia']].copy()\n",
    "                    \n",
    "                    # Reemplazar comas con puntos en los campos 'tmed' y 'hrMedia'\n",
    "                    df_final['tmed'] = df_final['tmed'].str.replace(',', '.', regex=False)\n",
    "                    df_final['hrMedia'] = df_final['hrMedia'].str.replace(',', '.', regex=False)\n",
    "                    \n",
    "                    # Convertir los campos 'tmed' y 'hrMedia' a tipo numérico\n",
    "                    df_final['tmed'] = pd.to_numeric(df_final['tmed'], errors='coerce')\n",
    "                    df_final['hrMedia'] = pd.to_numeric(df_final['hrMedia'], errors='coerce')\n",
    "                    \n",
    "                    # Agrupar por provincia y fecha y calcular la media de 'tmed' y 'hrMedia'\n",
    "                    df_provincia_fecha = df_final.groupby(['provincia', 'fecha']).agg({\n",
    "                        'tmed': 'mean',\n",
    "                        'hrMedia': 'mean'\n",
    "                    }).reset_index()\n",
    "                    \n",
    "                    # Agrupar por fecha para obtener la media total peninsular\n",
    "                    df_agrupado = df_provincia_fecha.groupby('fecha').agg({\n",
    "                        'tmed': 'mean',\n",
    "                        'hrMedia': 'mean'\n",
    "                    }).reset_index()\n",
    "                    \n",
    "                    return df_agrupado\n",
    "                else:\n",
    "                    print(\"La estructura de los datos no es una lista.\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Error al obtener los datos reales: {response_datos.status_code}\")\n",
    "        else:\n",
    "            print(\"No se encontró la URL de los datos reales en la respuesta.\")\n",
    "    else:\n",
    "        print(f\"Error en la solicitud inicial: {response.status_code}, {response.text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>tmed</th>\n",
       "      <th>hrMedia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>12.010493</td>\n",
       "      <td>63.451175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha       tmed    hrMedia\n",
       "0  2022-01-01  12.010493  63.451175"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "api_key = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJncmVnb3Jpb3ZhbHZlcmRlOEBnbWFpbC5jb20iLCJqdGkiOiJkZGYyMDUzMy1lYmZmLTQ5MmUtOGYzNi05ZTE0YjEyNjUzZWUiLCJpc3MiOiJBRU1FVCIsImlhdCI6MTcyNTk5NDA0NiwidXNlcklkIjoiZGRmMjA1MzMtZWJmZi00OTJlLThmMzYtOWUxNGIxMjY1M2VlIiwicm9sZSI6IiJ9.zgqzThSKPnGhAikI7O601zI9CTHsklcQ7Mk1UX83K-I'\n",
    "# Reemplaza con tu API key\n",
    "fecha_inicio = '2022-01-01T00:00:00UTC'\n",
    "fecha_fin = '2022-01-01T00:00:00UTC'\n",
    "datos_climaticos_df = obtener_datos_climaticos(fecha_inicio, fecha_fin, api_key)\n",
    "\n",
    "#if datos_climaticos_df is not None:\n",
    "#   print(datos_climaticos_df)\n",
    "\n",
    "datos_climaticos_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Asegúrate de importar el módulo time\n",
    "\n",
    "def datos_climaticos_anuales(year, api_key):\n",
    "    # Definir el rango de fechas para el año completo\n",
    "    fecha_inicio = f\"{year}-01-01T00:00:00UTC\"\n",
    "    fecha_final = f\"{year}-12-31T23:59:59UTC\"\n",
    "    \n",
    "    # Crear una lista para almacenar los DataFrames de cada intervalo\n",
    "    dfs = []\n",
    "    \n",
    "    # Iterar por cada intervalo de 10 días\n",
    "    fecha_actual = datetime.strptime(f\"{year}-01-01\", '%Y-%m-%d')\n",
    "    fecha_final = datetime.strptime(f\"{year}-12-31\", '%Y-%m-%d')\n",
    "    \n",
    "    while fecha_actual <= fecha_final:\n",
    "        # Definir el rango de fechas para el intervalo actual\n",
    "        fecha_str_inicio = fecha_actual.strftime('%Y-%m-%dT00:00:00UTC')\n",
    "        fecha_str_fin = (fecha_actual + timedelta(days=9)).strftime('%Y-%m-%dT23:59:59UTC')\n",
    "        \n",
    "        # Asegurarse de no exceder la fecha final del año\n",
    "        if fecha_str_fin > f\"{year}-12-31T23:59:59UTC\":\n",
    "            fecha_str_fin = f\"{year}-12-31T23:59:59UTC\"\n",
    "        \n",
    "        # Obtener datos del intervalo actual\n",
    "        df_intervalo = obtener_datos_climaticos(fecha_str_inicio, fecha_str_fin, api_key)\n",
    "        \n",
    "        if df_intervalo is not None:\n",
    "            dfs.append(df_intervalo)\n",
    "        \n",
    "        # Pasar al siguiente intervalo de 10 días\n",
    "        fecha_actual += timedelta(days=10)\n",
    "        \n",
    "        # Retraso para evitar exceder el límite de peticiones\n",
    "        time.sleep(1)  # Esperar 1 segundo antes de la siguiente solicitud\n",
    "    \n",
    "    # Concatenar todos los DataFrames y calcular la media para cada fecha\n",
    "    df_anual = pd.concat(dfs).groupby('fecha').agg({\n",
    "        'tmed': 'mean',\n",
    "        'hrMedia': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    return df_anual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_datos_climaticos_csv(df, year, archivo=None):\n",
    "    if archivo is None:\n",
    "        archivo = f'datos_climaticos_{year}.csv'\n",
    "    # Guardar el DataFrame en un archivo CSV\n",
    "    df.to_csv(archivo, index=False)\n",
    "\n",
    "year = 2019\n",
    "api_key = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJncmVnb3Jpb3ZhbHZlcmRlOEBnbWFpbC5jb20iLCJqdGkiOiJkZGYyMDUzMy1lYmZmLTQ5MmUtOGYzNi05ZTE0YjEyNjUzZWUiLCJpc3MiOiJBRU1FVCIsImlhdCI6MTcyNTk5NDA0NiwidXNlcklkIjoiZGRmMjA1MzMtZWJmZi00OTJlLThmMzYtOWUxNGIxMjY1M2VlIiwicm9sZSI6IiJ9.zgqzThSKPnGhAikI7O601zI9CTHsklcQ7Mk1UX83K-I'\n",
    "df_anual = datos_climaticos_anuales(year, api_key)\n",
    "guardar_datos_climaticos_csv(df_anual, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontró la URL de los datos reales en la respuesta.\n",
      "No se encontró la URL de los datos reales en la respuesta.\n",
      "No se encontró la URL de los datos reales en la respuesta.\n",
      "No se encontró la URL de los datos reales en la respuesta.\n",
      "No se encontró la URL de los datos reales en la respuesta.\n",
      "No se encontró la URL de los datos reales en la respuesta.\n",
      "No se encontró la URL de los datos reales en la respuesta.\n",
      "No se encontró la URL de los datos reales en la respuesta.\n",
      "No se encontró la URL de los datos reales en la respuesta.\n",
      "No se encontró la URL de los datos reales en la respuesta.\n",
      "No se encontró la URL de los datos reales en la respuesta.\n"
     ]
    }
   ],
   "source": [
    "Años = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "\n",
    "for year in Años:\n",
    "    df_anual = datos_climaticos_anuales(year, api_key)\n",
    "    guardar_datos_climaticos_csv(df_anual, year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
