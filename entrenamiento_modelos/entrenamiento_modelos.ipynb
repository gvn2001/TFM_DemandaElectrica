{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pmdarima import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from skforecast.ForecasterSarimax import ForecasterSarimax\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from sklearn.feature_selection import RFECV\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection import bayesian_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.model_selection_sarimax import backtesting_sarimax\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO DE MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datos_preprocesados.csv\", parse_dates=['fecha'], index_col='fecha')\n",
    "df = df.asfreq('D')\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates train      : 2019-01-01 00:00:00 --- 2023-08-12 00:00:00  (n=1685)\n",
      "Dates test       : 2023-08-12 00:00:00 --- 2024-09-26 00:00:00  (n=412)\n"
     ]
    }
   ],
   "source": [
    "# Divisiones de los datos en los conjuntos de entrenamiento y test\n",
    "end_train = '2023-08-12'\n",
    "\n",
    "data_train = df.loc[:end_train]\n",
    "data_test  = df.loc[end_train:]\n",
    "\n",
    "print(f\"Dates train      : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Dates test       : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para ARIMA y ARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenamiento del modelo ARIMA. No usa optimizador.\n",
    "\n",
    "def arima(p, d, q, maxiter):\n",
    "    forecaster = ForecasterSarimax( regressor=ARIMA(order=(p, d, q), seasonal_order=(0, 0, 0, 0), maxiter=maxiter))\n",
    "    \n",
    "    metric, predictions = backtesting_sarimax(\n",
    "        forecaster         = forecaster,\n",
    "        y                  = df['demanda'],\n",
    "        steps              = 1,\n",
    "        metric             = 'mean_absolute_error',\n",
    "        initial_train_size = len(data_train),\n",
    "        fixed_train_size   = False,       \n",
    "        refit              = False,\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "    return metric.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenamiento del modelo ARIMAX. No usa optimizador.\n",
    "\n",
    "def arimax(exog_features, p, d, q, maxiter):\n",
    "    forecaster = ForecasterSarimax( regressor=ARIMA(order=(p, d, q), seasonal_order=(0, 0, 0, 0), maxiter=maxiter))\n",
    "    \n",
    "    metric, predictions = backtesting_sarimax(\n",
    "        forecaster         = forecaster,\n",
    "        y                  = df['demanda'],\n",
    "        exog               = df[exog_features],\n",
    "        steps              = 1,\n",
    "        metric             = 'mean_absolute_error',\n",
    "        initial_train_size = len(data_train),\n",
    "        fixed_train_size   = False,       \n",
    "        refit              = False,\n",
    "        verbose            = False,\n",
    "        show_progress      = False\n",
    "    )\n",
    "    return metric.iloc[0]          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para un modelo genérico con variables exógenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_model(modelo, df, lags, exog_features, search_space, n_iter):\n",
    "\n",
    "    if modelo == 'decision_tree':\n",
    "        forecaster = ForecasterAutoreg(regressor = DecisionTreeRegressor(random_state=15926), lags = lags)\n",
    "\n",
    "    if modelo == 'random_forest':\n",
    "        forecaster = ForecasterAutoreg(regressor = RandomForestRegressor(random_state=151226), lags = lags)\n",
    "\n",
    "    if modelo == 'xgboost':\n",
    "        forecaster = ForecasterAutoreg(regressor = XGBRegressor(random_state=15942), lags = lags)\n",
    "    \n",
    "\n",
    "    results_search, frozen_trial = bayesian_search_forecaster(\n",
    "    forecaster         = forecaster,\n",
    "    y                  = df['demanda'],\n",
    "    exog               = df[exog_features],\n",
    "    search_space       = search_space,\n",
    "    steps              = 1,\n",
    "    refit              = False,\n",
    "    metric             = 'mean_absolute_error',\n",
    "    initial_train_size = len(data_train),\n",
    "    fixed_train_size   = False,\n",
    "    n_trials           = n_iter,\n",
    "    random_state       = 123,\n",
    "    return_best        = True,\n",
    "    n_jobs             = 'auto',\n",
    "    verbose            = False,\n",
    "    show_progress      = False\n",
    "    )\n",
    "    \n",
    "    best_params = results_search['params'].iat[0]\n",
    "\n",
    "    metric, predictions = backtesting_forecaster(\n",
    "    forecaster         = forecaster,\n",
    "    y                  = df['demanda'],\n",
    "    exog               = df[exog_features],\n",
    "    steps              = 1,\n",
    "    metric             = 'mean_absolute_error',\n",
    "    initial_train_size = len(data_train),\n",
    "    refit              = False,\n",
    "    n_jobs             = 'auto',\n",
    "    verbose            = False,\n",
    "    show_progress      = False\n",
    "    )\n",
    "\n",
    "    return predictions, best_params, metric.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de modelos ARIMA y ARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_features = ['diasem', 'trim', 'festivo']\n",
    "maxiter = 50\n",
    "\n",
    "# Definir los rangos para p, d y q\n",
    "range_values = range(1, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARA EL MODELO ARIMAX\n",
      "VARIABLES EXOGENAS: ['diasem', 'trim', 'festivo']\n",
      "Tiempo de ejecución: 10.93 segundos\n",
      "p = 1.0, d = 1.0, q = 1.0, MAE = 1135.6786522360646\n"
     ]
    }
   ],
   "source": [
    "# Ignorar advertencias específicas de statsmodels\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Non-stationary starting autoregressive parameters found\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Non-invertible starting MA parameters found\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"Series.__getitem__ treating keys as positions is deprecated\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Crear una lista para almacenar los resultados\n",
    "results = []\n",
    "\n",
    "# Iterar sobre los valores de p, d, q\n",
    "for p in range_values:\n",
    "    for d in range_values:\n",
    "        for q in range_values:\n",
    "            # Llamar a la función arimax con los parámetros actuales\n",
    "            metrica = arimax(exog_features, p, d, q, maxiter)\n",
    "            \n",
    "            # Si la métrica es un DataFrame o una Serie, extrae el valor escalar\n",
    "            if isinstance(metrica, pd.Series):\n",
    "                metrica_value = metrica.iloc[0]  # Extrae el primer valor\n",
    "            else:\n",
    "                metrica_value = metrica  # Asume que ya es un valor escalar\n",
    "\n",
    "            # Agregar los resultados a la lista\n",
    "            results.append({'p': p, 'd': d, 'q': q, 'MAE': metrica_value})\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "results_df = pd.DataFrame(results).min()\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print(f'PARA EL MODELO ARIMAX')\n",
    "print(f'VARIABLES EXOGENAS: {exog_features}')\n",
    "print(f'Tiempo de ejecución: {end_time:.2f} segundos')\n",
    "print(f'p = {results_df[0]}, d = {results_df[1]}, q = {results_df[2]}, MAE = {results_df[3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de modelo árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = 'decision_tree'\n",
    "\n",
    "exog_features = []\n",
    "\n",
    "lags = 7\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space = {\n",
    "        'max_depth'             : trial.suggest_int('max_depth', 3, 20, step=1),                  # Profundidad máxima del árbol\n",
    "        'max_leaf_nodes'        : trial.suggest_int('max_leaf_nodes', 30, 70, step=1),            # Máximo número de hojas en el árbol\n",
    "        'min_samples_leaf'      : trial.suggest_int('min_samples_leaf', 1, 10, step=1),          # Mínimo de muestras por hoja\n",
    "        'min_samples_split'     : trial.suggest_int('min_samples_split', 2, 20, step=1),         # Mínimo de muestras para dividir un nodo\n",
    "    }\n",
    "    return search_space\n",
    "\n",
    "n_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6 7] \n",
      "  Parameters: {'max_depth': 17, 'max_leaf_nodes': 54, 'min_samples_leaf': 8, 'min_samples_split': 2}\n",
      "  Backtesting metric: 946.2451675634615\n",
      "\n",
      "PARA EL MODELO decision_tree\n",
      "VARIABLES EXOGENAS: []\n",
      "Tiempo de ejecución: 67.81 segundos\n",
      "mean_absolute_error    946.245168\n",
      "Name: 0, dtype: float64\n",
      "HIPERPARAMETROS: {'max_depth': 17, 'max_leaf_nodes': 54, 'min_samples_leaf': 8, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "resultado = generic_model(modelo, df, 7, exog_features, search_space, n_iter)\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print(f'PARA EL MODELO {modelo}')\n",
    "print(f'VARIABLES EXOGENAS: {exog_features}')\n",
    "print(f'Tiempo de ejecución: {end_time:.2f} segundos')\n",
    "print(f'{resultado[2]}')\n",
    "print(f'HIPERPARAMETROS: {resultado[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_features = ['diasem', 'trim', 'festivo']\n",
    "maxiter = 50\n",
    "\n",
    "# Definir los rangos para p, d y q\n",
    "range_values = range(1, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GregorioValverdeNava\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\GregorioValverdeNava\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e50c216ec7645ab9e1f5b4cdaba193b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "p         1.000000\n",
       "d         1.000000\n",
       "q         1.000000\n",
       "MAE    1135.678652\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Crear una lista para almacenar los resultados\n",
    "results = []\n",
    "\n",
    "# Iterar sobre los valores de p, d, q\n",
    "for p in range_values:\n",
    "    for d in range_values:\n",
    "        for q in range_values:\n",
    "            # Llamar a la función arimax con los parámetros actuales\n",
    "            metrica = arimax(exog_features, p, d, q, maxiter)\n",
    "            \n",
    "            # Si la métrica es un DataFrame o una Serie, extrae el valor escalar\n",
    "            if isinstance(metrica, pd.Series):\n",
    "                metrica_value = metrica.iloc[0]  # Extrae el primer valor\n",
    "            else:\n",
    "                metrica_value = metrica  # Asume que ya es un valor escalar\n",
    "\n",
    "            # Agregar los resultados a la lista\n",
    "            results.append({'p': p, 'd': d, 'q': q, 'MAE': metrica_value})\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Guardar el DataFrame en un archivo Excel\n",
    "df_results.min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = 'random_forest'\n",
    "\n",
    "exog_features = []\n",
    "\n",
    "lags = 7\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space = {\n",
    "        'max_depth'             : trial.suggest_int('max_depth', 3, 20, step=1),                  # Profundidad máxima del árbol\n",
    "        'max_leaf_nodes'        : trial.suggest_int('max_leaf_nodes', 30, 70, step=1),            # Máximo número de hojas en el árbol\n",
    "        'min_samples_leaf'      : trial.suggest_int('min_samples_leaf', 1, 10, step=1),          # Mínimo de muestras por hoja\n",
    "        'min_samples_split'     : trial.suggest_int('min_samples_split', 2, 20, step=1),         # Mínimo de muestras para dividir un nodo\n",
    "        'max_samples'           : trial.suggest_float('max_samples', 0.5, 1.0)\n",
    "    }\n",
    "    return search_space\n",
    "\n",
    "n_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6 7] \n",
      "  Parameters: {'max_depth': 15, 'max_leaf_nodes': 41, 'min_samples_leaf': 3, 'min_samples_split': 12, 'max_samples': 0.8597344848927815}\n",
      "  Backtesting metric: 902.6027192973853\n",
      "\n",
      "PARA EL MODELO random_forest\n",
      "VARIABLES EXOGENAS: []\n",
      "HIPERPARAMETROS: {'max_depth': 15, 'max_leaf_nodes': 41, 'min_samples_leaf': 3, 'min_samples_split': 12, 'max_samples': 0.8597344848927815}\n",
      "mean_absolute_error    902.602719\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "resultado = generic_model(modelo, df, 7, exog_features, search_space, n_iter)\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print(f'PARA EL MODELO {modelo}')\n",
    "print(f'VARIABLES EXOGENAS: {exog_features}')\n",
    "print(f'Tiempo de ejecución: {end_time:.2f} segundos')\n",
    "print(f'{resultado[2]}')\n",
    "print(f'HIPERPARAMETROS: {resultado[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = 'xgboost'\n",
    "\n",
    "exog_features = []\n",
    "\n",
    "lags = 7\n",
    "\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 200, 1000, step=100),\n",
    "        'max_depth'       : trial.suggest_int('max_depth', 3, 10, step=1),\n",
    "        'learning_rate'   : trial.suggest_float('learning_rate', 0.01, 1),\n",
    "        'subsample'       : trial.suggest_float('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n",
    "        'gamma'           : trial.suggest_float('gamma', 0, 1),\n",
    "        'reg_alpha'       : trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda'      : trial.suggest_float('reg_lambda', 0, 1),\n",
    "    } \n",
    "    return search_space\n",
    "\n",
    "n_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5 6 7] \n",
      "  Parameters: {'n_estimators': 800, 'max_depth': 5, 'learning_rate': 0.2345829390285611, 'subsample': 0.5961832921746021, 'colsample_bytree': 0.7475220728070068, 'gamma': 0.42310646012446096, 'reg_alpha': 0.9807641983846155, 'reg_lambda': 0.6848297385848633}\n",
      "  Backtesting metric: 956.3783939704987\n",
      "\n",
      "PARA EL MODELO xgboost\n",
      "VARIABLES EXOGENAS: []\n",
      "Tiempo de ejecución: 6.47 segundos\n",
      "mean_absolute_error    956.378394\n",
      "Name: 0, dtype: float64\n",
      "HIPERPARAMETROS: {'n_estimators': 800, 'max_depth': 5, 'learning_rate': 0.2345829390285611, 'subsample': 0.5961832921746021, 'colsample_bytree': 0.7475220728070068, 'gamma': 0.42310646012446096, 'reg_alpha': 0.9807641983846155, 'reg_lambda': 0.6848297385848633}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "resultado = generic_model(modelo, df, 7, exog_features, search_space, n_iter)\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print(f'PARA EL MODELO {modelo}')\n",
    "print(f'VARIABLES EXOGENAS: {exog_features}')\n",
    "print(f'Tiempo de ejecución: {end_time:.2f} segundos')\n",
    "print(f'{resultado[2]}')\n",
    "print(f'HIPERPARAMETROS: {resultado[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REPRESENTACIÓN GRÁFICA DE LOS RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = resultado[0]\n",
    "\n",
    "plt.figure(figsize=(10, 5))  # Define el tamaño de la figura\n",
    "plt.plot(data_test.index, data_test['demanda'], label=\"Real Value\", color='blue', linestyle='-') # Valores reales\n",
    "plt.plot(predictions.index, predictions['pred'], label=\"Predictions\", color='orange', linestyle='--') # Valores predichos\n",
    "\n",
    "# Configurar el título y las etiquetas\n",
    "plt.title(\"Real Value vs Predicted in Test Data\")\n",
    "plt.xlabel(\"Date Time\")\n",
    "plt.ylabel(\"Users\")\n",
    "\n",
    "# Añadir leyenda\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.grid()  # Añadir cuadrícula para mejor visualización\n",
    "plt.tight_layout()  # Ajustar el layout\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
